import asyncio
import random
import time
import os
from playwright.async_api import async_playwright
import gspread
from datetime import datetime

SERVICE_ACCOUNT_FILE = 'service_account2020.json' 
SHEET_URL = 'https://docs.google.com/spreadsheets/d/1omDVgsy4qwCKZMbuDLoKvJjNsOU1uqkfBqZIM7euezk/edit?gid=0#gid=0'

# ğŸ”¥ 37ê°œ ê°¤ëŸ¬ë¦¬ ì •ë‹µ ì£¼ì†Œ ë¦¬ìŠ¤íŠ¸ (ë³€ê²½ ì—†ìŒ)
ALL_GALLERIES = [
    {"name": "4ë…„ì œëŒ€í•™ê°¤ëŸ¬ë¦¬", "pc": "https://gall.dcinside.com/board/lists/?id=4year_university", "mo": "https://m.dcinside.com/board/4year_university"},
    {"name": "7ê¸‰ê³µë¬´ì›ê°¤ëŸ¬ë¦¬", "pc": "https://gall.dcinside.com/board/lists/?id=7th", "mo": "https://m.dcinside.com/board/7th"},
    {"name": "ê³ ì‹œì‹œí—˜ê°¤ëŸ¬ë¦¬", "pc": "https://gall.dcinside.com/board/lists/?id=exam_new", "mo": "https://m.dcinside.com/board/exam_new"},
    {"name": "ê³µë¬´ì›ê°¤ëŸ¬ë¦¬", "pc": "https://gall.dcinside.com/board/lists/?id=government", "mo": "https://m.dcinside.com/board/government"},
    {"name": "ëŒ€í•™ê°¤ëŸ¬ë¦¬", "pc": "https://gall.dcinside.com/board/lists/?id=univ_new", "mo": "https://m.dcinside.com/board/univ_new"},
    {"name": "ë²•í•™ì „ë¬¸ëŒ€í•™ì›ê°¤ëŸ¬ë¦¬", "pc": "https://gall.dcinside.com/board/lists/?id=lawschool", "mo": "https://m.dcinside.com/board/lawschool"},
    {"name": "ì„¸ë¬´ì‚¬ê°¤ëŸ¬ë¦¬", "pc": "https://gall.dcinside.com/board/lists/?id=cta", "mo": "https://m.dcinside.com/board/cta"},
    {"name": "ì†Œë°©ê°¤ëŸ¬ë¦¬", "pc": "https://gall.dcinside.com/board/lists/?id=fire", "mo": "https://m.dcinside.com/board/fire"},
    {"name": "ìˆœê²½ê°¤ëŸ¬ë¦¬", "pc": "https://gall.dcinside.com/board/lists/?id=policeofficer", "mo": "https://m.dcinside.com/board/policeofficer"},
    {"name": "ì–´í•™ì—°ìˆ˜ê°¤ëŸ¬ë¦¬", "pc": "https://gall.dcinside.com/board/lists/?id=language", "mo": "https://m.dcinside.com/board/language"},
    {"name": "ì˜ì–´ê°¤ëŸ¬ë¦¬", "pc": "https://gall.dcinside.com/board/lists/?id=English", "mo": "https://m.dcinside.com/board/English"},
    {"name": "ì¼ì–´ê°¤ëŸ¬ë¦¬", "pc": "https://gall.dcinside.com/board/lists/?id=japanese", "mo": "https://m.dcinside.com/board/japanese"},
    {"name": "ì„ìš©ê³ ì‹œê°¤ëŸ¬ë¦¬", "pc": "https://gall.dcinside.com/board/lists/?id=imyoung", "mo": "https://m.dcinside.com/board/imyoung"},
    {"name": "ìê²©ì¦ê°¤ëŸ¬ë¦¬", "pc": "https://gall.dcinside.com/board/lists/?id=coq", "mo": "https://m.dcinside.com/board/coq"},
    {"name": "ì¤‘êµ­ì–´ê°¤ëŸ¬ë¦¬", "pc": "https://gall.dcinside.com/board/lists/?id=chinese", "mo": "https://m.dcinside.com/board/chinese"},
    {"name": "í† ìµê°¤ëŸ¬ë¦¬", "pc": "https://gall.dcinside.com/board/lists/?id=toeic", "mo": "https://m.dcinside.com/board/toeic"},
    {"name": "í† í”Œê°¤ëŸ¬ë¦¬", "pc": "https://gall.dcinside.com/board/lists/?id=toefl", "mo": "https://m.dcinside.com/board/toefl"},
    {"name": "í¸ì…ê°¤ëŸ¬ë¦¬", "pc": "https://gall.dcinside.com/board/lists/?id=admission", "mo": "https://m.dcinside.com/board/admission"},
    {"name": "í•™ì ì€í–‰ì œê°¤ëŸ¬ë¦¬", "pc": "https://gall.dcinside.com/board/lists/?id=acbs", "mo": "https://m.dcinside.com/board/acbs"},
    {"name": "í•´ì–‘ê²½ì°°ê°¤ëŸ¬ë¦¬", "pc": "https://gall.dcinside.com/board/lists/?id=kcg", "mo": "https://m.dcinside.com/board/kcg"},
    {"name": "íšŒê³„ì‚¬ê°¤ëŸ¬ë¦¬", "pc": "https://gall.dcinside.com/board/lists/?id=cpa", "mo": "https://m.dcinside.com/board/cpa"},

    {"name": "HSKê°¤ëŸ¬ë¦¬", "pc": "https://gall.dcinside.com/mgallery/board/lists/?id=hsk123456", "mo": "https://m.dcinside.com/board/hsk123456"},
    {"name": "JLPTê°¤ëŸ¬ë¦¬", "pc": "https://gall.dcinside.com/mgallery/board/lists/?id=jlpt", "mo": "https://m.dcinside.com/board/jlpt"},
    {"name": "ê³µì¸ì¤‘ê°œì‚¬ê°¤ëŸ¬ë¦¬", "pc": "https://gall.dcinside.com/mgallery/board/lists/?id=bokdukbang", "mo": "https://m.dcinside.com/board/bokdukbang"},
    {"name": "êµ°ë¬´ì›ê°¤ëŸ¬ë¦¬", "pc": "https://gall.dcinside.com/mgallery/board/lists/?id=soider", "mo": "https://m.dcinside.com/board/soider"},
    {"name": "ë“€ì˜¤ë§ê³ ê°¤ëŸ¬ë¦¬", "pc": "https://gall.dcinside.com/mgallery/board/lists/?id=duolingo", "mo": "https://m.dcinside.com/board/duolingo"},
    {"name": "ëŸ¬ì‹œì•„ì–´ê°¤ëŸ¬ë¦¬", "pc": "https://gall.dcinside.com/mgallery/board/lists/?id=russiangall", "mo": "https://m.dcinside.com/board/russiangall"},
    {"name": "ë§ˆì´ìŠ¤í„°ê³ ê°¤ëŸ¬ë¦¬", "pc": "https://gall.dcinside.com/mgallery/board/lists/?id=meister", "mo": "https://m.dcinside.com/board/meister"},
    {"name": "ì˜ì–´íšŒí™”ê°¤ëŸ¬ë¦¬", "pc": "https://gall.dcinside.com/mgallery/board/lists/?id=englishspeech", "mo": "https://m.dcinside.com/board/englishspeech"},
    {"name": "ì˜¤í”½ê°¤ëŸ¬ë¦¬", "pc": "https://gall.dcinside.com/mgallery/board/lists/?id=opic", "mo": "https://m.dcinside.com/board/opic"},
    {"name": "ìœ í•™ì‹œí—˜ê°¤ëŸ¬ë¦¬", "pc": "https://gall.dcinside.com/mgallery/board/lists/?id=eju", "mo": "https://m.dcinside.com/board/eju"},
    {"name": "ì „ì‚°ì„¸ë¬´íšŒê³„ê°¤ëŸ¬ë¦¬", "pc": "https://gall.dcinside.com/mgallery/board/lists/?id=accounting", "mo": "https://m.dcinside.com/board/accounting"},
    {"name": "ì •ë³‘ê¶Œê°¤ëŸ¬ë¦¬", "pc": "https://gall.dcinside.com/mgallery/board/lists/?id=jeongbyeongkwon", "mo": "https://m.dcinside.com/board/jeongbyeongkwon"},
    {"name": "ì§€í…”í”„ê°¤ëŸ¬ë¦¬", "pc": "https://gall.dcinside.com/mgallery/board/lists/?id=gtelp", "mo": "https://m.dcinside.com/board/gtelp"},
    {"name": "ì»´í“¨í„°í™œìš©ëŠ¥ë ¥ê°¤ëŸ¬ë¦¬", "pc": "https://gall.dcinside.com/mgallery/board/lists/?id=cbt", "mo": "https://m.dcinside.com/board/cbt"},
    {"name": "í…ìŠ¤ê°¤ëŸ¬ë¦¬", "pc": "https://gall.dcinside.com/mgallery/board/lists/?id=tepstopia", "mo": "https://m.dcinside.com/board/tepstopia"},
    {"name": "í† ìµìŠ¤í”¼í‚¹ê°¤ëŸ¬ë¦¬", "pc": "https://gall.dcinside.com/mgallery/board/lists/?id=toeicspeaking", "mo": "https://m.dcinside.com/board/toeicspeaking"}
]

CHUNK_INDEX = int(os.getenv("CHUNK_INDEX", 0))
TOTAL_CHUNKS = int(os.getenv("TOTAL_CHUNKS", 1))

base_size = len(ALL_GALLERIES) // TOTAL_CHUNKS 
remainder = len(ALL_GALLERIES) % TOTAL_CHUNKS   

if CHUNK_INDEX < remainder:
    start_idx = CHUNK_INDEX * (base_size + 1)
    end_idx = start_idx + (base_size + 1)
else:
    start_idx = remainder * (base_size + 1) + (CHUNK_INDEX - remainder) * base_size
    end_idx = start_idx + base_size

TARGET_GALLERIES = ALL_GALLERIES[start_idx:end_idx]

def safe_batch_upload(ws, data_chunk):
    if not data_chunk: return
    rows = [[d['date'], d['gallery'], d['env'], d['pos'], d['url'], d['img'], d['text']] for d in data_chunk]
    for i in range(0, len(rows), 30):
        try:
            ws.append_rows(rows[i:i+30])
            time.sleep(1.5)
        except Exception: time.sleep(5)

async def uploader_worker(queue, ws):
    buffer = []
    while True:
        item = await queue.get()
        if item is None: break
        buffer.append(item)
        if len(buffer) >= 100:
            print(f"ğŸš€ [ì„œë²„ {CHUNK_INDEX+1}] 100ê°œ ë„ë‹¬! ì¤‘ê°„ ì—…ë¡œë“œ ì¤‘...")
            await asyncio.to_thread(safe_batch_upload, ws, buffer)
            buffer.clear()
        queue.task_done()
    if buffer:
        await asyncio.to_thread(safe_batch_upload, ws, buffer)

def get_korean_position(env, page_type, raw_pos, img_src):
    raw = str(raw_pos).lower()
    if not img_src: return "í…ìŠ¤íŠ¸ë°°ë„ˆ"
    if "icon" in raw or "float" in raw or "pop-layer" in raw: return "ì•„ì´ì½˜ë°°ë„ˆ"
    if env == "PC":
        if page_type == "ë³¸ë¬¸": return "í•˜ë‹¨ë°°ë„ˆ" if "bottom" in raw or "btm" in raw else "ê²Œì‹œê¸€ë°°ë„ˆ"
        else:
            if "right" in raw or "wing" in raw: return "ìš°ì¸¡ë°°ë„ˆ"
            if "left" in raw: return "ì¢Œì¸¡ë°°ë„ˆ"
            return "í•˜ë‹¨ë°°ë„ˆ" if "bottom" in raw or "btm" in raw else "ìƒë‹¨ë°°ë„ˆ"
    else: 
        if page_type == "ë³¸ë¬¸": return "í•˜ë‹¨ë°°ë„ˆ" if "bottom" in raw or "btm" in raw else "ê²Œì‹œê¸€ë°°ë„ˆ"
        else: return "í•˜ë‹¨ë°°ë„ˆ" if "bottom" in raw or "btm" in raw else "ìƒë‹¨ë°°ë„ˆ"

async def get_final_landing_url(context, redirect_url):
    if not redirect_url or "addc.dcinside" not in redirect_url: return redirect_url
    try:
        temp = await context.new_page()
        await temp.goto(redirect_url, wait_until="commit", timeout=4000)
        url = temp.url
        await temp.close()
        return url
    except: return redirect_url

async def block_resources(route):
    if route.request.resource_type in ["font", "media"]: await route.abort()
    else: await route.continue_()

async def capture_ads(context, page, env, gallery, page_type):
    collected, seen = [], set()
    today = datetime.now().strftime("%Y-%m-%d")
    
    # ì¡°ê¸° ì¢…ë£Œ ì¡°ê±´: ê´‘ê³ ë¥¼ ì°¾ìœ¼ë©´ ë¹ ë¥´ê²Œ 5íšŒ ì‹œë„ í›„ ì¢…ë£Œ
    valid_refreshes, attempt = 0, 0
    prefix = f"[ì„œë²„ {CHUNK_INDEX+1}|{env}|{gallery[:4]}|{page_type}]"
    
    while valid_refreshes < 5 and attempt < 10:
        attempt += 1; found_ad_in_this_round = False
        current_round = valid_refreshes + 1
        ad_count_in_round = 0
        try:
            await page.reload(wait_until="load", timeout=12000)
            await asyncio.sleep(2)
            await page.evaluate("window.scrollTo(0, document.body.scrollHeight / 3);")
            await asyncio.sleep(0.5)
            await page.evaluate("window.scrollTo(0, document.body.scrollHeight / 1.5);")
            await asyncio.sleep(0.5)
            await page.evaluate("window.scrollTo(0, document.body.scrollHeight);")
            await asyncio.sleep(1)
        except: pass

        for frame in page.frames:
            try:
                for ad in await frame.locator("a").all():
                    raw_href = await ad.get_attribute("href") or ""
                    
                    img_src = await ad.evaluate("""n => {
                        let img = n.querySelector('img');
                        if (img) {
                            if (img.src && !img.src.includes('data:image')) return img.src;
                            if (img.getAttribute('data-src')) return img.getAttribute('data-src');
                        }
                        let bg = window.getComputedStyle(n).backgroundImage;
                        if (bg && bg !== 'none' && bg.includes('url')) {
                            return bg.replace(/^url\\(['"]?/, '').replace(/['"]?\\)$/, '');
                        }
                        let child = n.querySelector('div, span');
                        if (child) {
                            let cbg = window.getComputedStyle(child).backgroundImage;
                            if (cbg && cbg !== 'none' && cbg.includes('url')) {
                                return cbg.replace(/^url\\(['"]?/, '').replace(/['"]?\\)$/, '');
                            }
                        }
                        return '';
                    }""")
                    
                    raw_pos = await ad.evaluate("n => { let p = n.closest('div'); return p ? p.className : ''; }")
                    txt = await ad.inner_text() or ""
                    
                    clean_href = raw_href.strip().lower()
                    clean_img = img_src.strip().lower()
                    clean_txt = txt.strip()
                    
                    # ğŸ”¥ [ì´ˆê°•ë ¥ í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ ê²€ì¦] ì§„ì§œ ê´‘ê³  DNAê°€ ìˆëŠ”ì§€ í™•ì¸!
                    # ì´ë¯¸ì§€ì— /ad/ ê°€ ìˆê±°ë‚˜, ë§í¬ì— addc.dc, netinsight ê°€ ìˆì–´ì•¼ë§Œ í†µê³¼
                    is_real_ad = False
                    if "/ad/" in clean_img or "addc.dc" in clean_href or "netinsight" in clean_href:
                        is_real_ad = True
                        
                    if not is_real_ad:
                        continue # ê°€ì§œ ì“°ë ˆê¸°(ê°¤ëŸ¬ë¦¬ UI, ì•„ì´ì½˜ ë“±)ëŠ” ì—¬ê¸°ì„œ ì „ë¶€ íŠ•ê²¨ë‚˜ê°!

                    # ì†ì´ í…… ë¹ˆ ìœ ë ¹ ë°ì´í„° ë°©ì–´
                    if not clean_img and not clean_txt: continue 

                    found_ad_in_this_round = True
                    key = clean_img or raw_href
                    if key not in seen:
                        seen.add(key)
                        ad_count_in_round += 1
                        
                        final_url = await get_final_landing_url(context, raw_href) if not raw_href.startswith("javascript") else raw_href
                        
                        # ğŸ”¥ [ì™„ë²½ í•´ê²°] __CLICK__ í…ìŠ¤íŠ¸ ì˜ˆì˜ê²Œ ì„¸íƒí•˜ê¸°
                        # 1. ì•„ì˜ˆ URLì´ __CLICK__ ê»ë°ê¸°ë¿ì´ë©´ ì•ˆë‚´ ë¬¸êµ¬ë¡œ êµì²´
                        if final_url.strip() in ["__CLICK__", "null", "#", ""]:
                            final_url = "ëœë”© URL ìˆ¨ê¹€ (í´ë¦­ ì´ë²¤íŠ¸)"
                        # 2. ê¸´ URL ì¤‘ê°„ì— __CLICK__ì´ ë¼ì–´ìˆìœ¼ë©´ í•´ë‹¹ ê¸€ìë§Œ ì‚­ì œ
                        elif "__CLICK__" in final_url.upper():
                            final_url = final_url.replace("__CLICK__", "").replace("__click__", "")
                        
                        # í˜¹ì‹œ ëª¨ë¥¼ ë‚´ë¶€ íŠ•ê¹€ ë§í¬ í•œ ë²ˆ ë” ì°¨ë‹¨
                        clean_final = final_url.rstrip('/').lower()
                        if clean_final in ["https://www.dcinside.com", "https://gall.dcinside.com", "https://m.dcinside.com", "https://gall.dcinside.com/m"]: 
                            final_url = "ëœë”© URL ìˆ¨ê¹€ (ë‚´ë¶€ ë³´ì•ˆ)"
                        
                        pos = get_korean_position(env, page_type, raw_pos, clean_img)
                        text_val = clean_txt if clean_txt else "ì´ë¯¸ì§€ ë°°ë„ˆ"
                        
                        print(f"âœ… {prefix} [{current_round}íšŒì°¨ ìƒˆë¡œê³ ì¹¨ - {ad_count_in_round}ë²ˆì§¸ ë°œê²¬] {pos}")
                        collected.append({"date": today, "gallery": gallery, "env": env, "pos": pos, "url": final_url, "img": img_src.strip(), "text": text_val})
            except: continue
        if found_ad_in_this_round: valid_refreshes += 1
    return collected

async def task_runner(sem, ctx, env, tgt, queue):
    async with sem:
        await asyncio.sleep(random.uniform(0, 1.5))
        page = await ctx.new_page()
        await page.route("**/*", block_resources)
        try:
            target_url = tgt['pc'] if env=="PC" else tgt['mo']
            
            gallery_id = ""
            if "id=" in target_url:
                gallery_id = target_url.split("id=")[-1].split("&")[0]
            else:
                gallery_id = target_url.split("/")[-1]

            await page.goto(target_url, wait_until="load", timeout=15000)
            await asyncio.sleep(1.5)
            
            # ğŸ”¥ 3ë‹¨ ìë™ ìš°íšŒ íƒìƒ‰
            current_url = page.url.lower()
            if gallery_id.lower() not in current_url:
                if env == "PC":
                    print(f"âš ï¸ [ì„œë²„ {CHUNK_INDEX+1}|{tgt['name']}] ì •ê·œ/ë§ˆì´ë„ˆ ì£¼ì†Œ ì‹¤íŒ¨. ìë™ íƒìƒ‰ ì‹œì‘...")
                    test_urls = [
                        f"https://gall.dcinside.com/board/lists/?id={gallery_id}",
                        f"https://gall.dcinside.com/mgallery/board/lists/?id={gallery_id}",
                        f"https://gall.dcinside.com/mini/board/lists/?id={gallery_id}"
                    ]
                    for t_url in test_urls:
                        await page.goto(t_url, wait_until="load", timeout=12000)
                        await asyncio.sleep(1.5)
                        if gallery_id.lower() in page.url.lower():
                            print(f"âœ… [ì„œë²„ {CHUNK_INDEX+1}|{tgt['name']}] ì˜¬ë°”ë¥¸ ì£¼ì†Œ ì•ˆì°© ì™„ë£Œ!")
                            break
                elif env == "MO":
                    print(f"âš ï¸ [ì„œë²„ {CHUNK_INDEX+1}|{tgt['name']}] ëª¨ë°”ì¼ ê¸°ë³¸ ì£¼ì†Œ ì‹¤íŒ¨. ìë™ íƒìƒ‰ ì‹œì‘...")
                    test_urls = [
                        f"https://m.dcinside.com/board/{gallery_id}",
                        f"https://m.dcinside.com/mini/{gallery_id}"
                    ]
                    for t_url in test_urls:
                        await page.goto(t_url, wait_until="load", timeout=12000)
                        await asyncio.sleep(1.5)
                        if gallery_id.lower() in page.url.lower():
                            print(f"âœ… [ì„œë²„ {CHUNK_INDEX+1}|{tgt['name']}] ì˜¬ë°”ë¥¸ ì£¼ì†Œ ì•ˆì°© ì™„ë£Œ!")
                            break

            for item in await capture_ads(ctx, page, env, tgt['name'], "ë¦¬ìŠ¤íŠ¸"): await queue.put(item)
            
            post = page.locator("tr.us-post:not(.notice) td.gall_tit > a:not(.reply_numbox)").first if env=="PC" else page.locator("ul.gall-detail-lst li:not(.notice) .gall-detail-lnktit a").first
            if await post.count() > 0:
                await post.click()
                await asyncio.sleep(2.5)
                for item in await capture_ads(ctx, page, env, tgt['name'], "ë³¸ë¬¸"): await queue.put(item)
        except: pass
        finally: await page.close()

async def main():
    if not TARGET_GALLERIES: return
    
    gallery_names = [g['name'] for g in TARGET_GALLERIES]
    print(f"ğŸ”¥ [ì„œë²„ {CHUNK_INDEX+1}] ê°€ë™! í• ë‹¹ëœ ê°¤ëŸ¬ë¦¬ {len(TARGET_GALLERIES)}ê°œ: {', '.join(gallery_names)}")
    
    gc = gspread.service_account(filename=SERVICE_ACCOUNT_FILE)
    ws = gc.open_by_url(SHEET_URL).get_worksheet(0)
    
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True, args=["--disable-blink-features=AutomationControlled", "--no-sandbox", "--disable-web-security"])
        pc_ctx, mo_ctx = await browser.new_context(viewport={"width": 1920, "height": 1080}), await browser.new_context(**p.devices['iPhone 13'])
        
        sem, queue = asyncio.Semaphore(5), asyncio.Queue()
        uploader = asyncio.create_task(uploader_worker(queue, ws))

        tasks = [task_runner(sem, pc_ctx, "PC", t, queue) for t in TARGET_GALLERIES] + [task_runner(sem, mo_ctx, "MO", t, queue) for t in TARGET_GALLERIES]
        await asyncio.gather(*tasks)
        await browser.close()
        
        await queue.put(None)
        await uploader
        print(f"ğŸ‰ [ì„œë²„ {CHUNK_INDEX+1}] ë‹´ë‹¹ êµ¬ì—­ ì™„ë²½í•˜ê²Œ ìˆ˜ì§‘ ì¢…ë£Œ!")

if __name__ == "__main__": asyncio.run(main())
