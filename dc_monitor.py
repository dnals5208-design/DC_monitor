import asyncio
import random
import time
import os
from playwright.async_api import async_playwright
import gspread
from datetime import datetime

SERVICE_ACCOUNT_FILE = 'service_account2020.json' 
SHEET_URL = 'https://docs.google.com/spreadsheets/d/1omDVgsy4qwCKZMbuDLoKvJjNsOU1uqkfBqZIM7euezk/edit?gid=0#gid=0'

ALL_GALLERIES = [
    {"name": "4ë…„ì œëŒ€í•™ê°¤ëŸ¬ë¦¬", "pc": "https://gall.dcinside.com/board/lists/?id=4year_university", "mo": "https://m.dcinside.com/board/4year_university"},
    {"name": "7ê¸‰ê³µë¬´ì›ê°¤ëŸ¬ë¦¬", "pc": "https://gall.dcinside.com/board/lists/?id=7th", "mo": "https://m.dcinside.com/board/7th"},
    {"name": "HSKê°¤ëŸ¬ë¦¬", "pc": "https://gall.dcinside.com/board/lists/?id=hsk123456", "mo": "https://m.dcinside.com/board/hsk123456"},
    {"name": "JLPTê°¤ëŸ¬ë¦¬", "pc": "https://gall.dcinside.com/board/lists/?id=jlpt", "mo": "https://m.dcinside.com/board/jlpt"},
    {"name": "ê³ ì‹œì‹œí—˜ê°¤ëŸ¬ë¦¬", "pc": "https://gall.dcinside.com/board/lists/?id=exam_new", "mo": "https://m.dcinside.com/board/exam_new"},
    {"name": "ê³µë¬´ì›ê°¤ëŸ¬ë¦¬", "pc": "https://gall.dcinside.com/board/lists/?id=government", "mo": "https://m.dcinside.com/board/government"},
    {"name": "ê³µì¸ì¤‘ê°œì‚¬ê°¤ëŸ¬ë¦¬", "pc": "https://gall.dcinside.com/board/lists/?id=lreaexam", "mo": "https://m.dcinside.com/board/lreaexam"},
    {"name": "êµ°ë¬´ì›ê°¤ëŸ¬ë¦¬", "pc": "https://gall.dcinside.com/board/lists/?id=soider", "mo": "https://m.dcinside.com/board/soider"},
    {"name": "ëŒ€í•™ê°¤ëŸ¬ë¦¬", "pc": "https://gall.dcinside.com/board/lists/?id=univ_new", "mo": "https://m.dcinside.com/board/univ_new"},
    {"name": "ë“€ì˜¤ë§ê³ ê°¤ëŸ¬ë¦¬", "pc": "https://gall.dcinside.com/board/lists/?id=duolingo", "mo": "https://m.dcinside.com/board/duolingo"},
    {"name": "ëŸ¬ì‹œì•„ì–´ê°¤ëŸ¬ë¦¬", "pc": "https://gall.dcinside.com/board/lists/?id=russiangall", "mo": "https://m.dcinside.com/board/russiangall"},
    {"name": "ë§ˆì´ìŠ¤í„°ê³ ê°¤ëŸ¬ë¦¬", "pc": "https://gall.dcinside.com/board/lists/?id=meister", "mo": "https://m.dcinside.com/board/meister"},
    {"name": "ë²•í•™ì „ë¬¸ëŒ€í•™ì›ê°¤ëŸ¬ë¦¬", "pc": "https://gall.dcinside.com/board/lists/?id=lawschool", "mo": "https://m.dcinside.com/board/lawschool"},
    {"name": "ì„¸ë¬´ì‚¬ê°¤ëŸ¬ë¦¬", "pc": "https://gall.dcinside.com/board/lists/?id=cta", "mo": "https://m.dcinside.com/board/cta"},
    {"name": "ì†Œë°©ê°¤ëŸ¬ë¦¬", "pc": "https://gall.dcinside.com/board/lists/?id=fire", "mo": "https://m.dcinside.com/board/fire"},
    {"name": "ìˆœê²½ê°¤ëŸ¬ë¦¬", "pc": "https://gall.dcinside.com/board/lists/?id=policeofficer", "mo": "https://m.dcinside.com/board/policeofficer"},
    {"name": "ì–´í•™ì—°ìˆ˜ê°¤ëŸ¬ë¦¬", "pc": "https://gall.dcinside.com/board/lists/?id=language", "mo": "https://m.dcinside.com/board/language"},
    {"name": "ì˜ì–´ê°¤ëŸ¬ë¦¬", "pc": "https://gall.dcinside.com/board/lists/?id=English", "mo": "https://m.dcinside.com/board/English"},
    {"name": "ì˜ì–´íšŒí™”ê°¤ëŸ¬ë¦¬", "pc": "https://gall.dcinside.com/board/lists/?id=englishspeech", "mo": "https://m.dcinside.com/board/englishspeech"},
    {"name": "ì˜¤í”½ê°¤ëŸ¬ë¦¬", "pc": "https://gall.dcinside.com/board/lists/?id=opic", "mo": "https://m.dcinside.com/board/opic"},
    {"name": "ìœ í•™ì‹œí—˜ê°¤ëŸ¬ë¦¬", "pc": "https://gall.dcinside.com/board/lists/?id=eju", "mo": "https://m.dcinside.com/board/eju"},
    {"name": "ì¼ì–´ê°¤ëŸ¬ë¦¬", "pc": "https://gall.dcinside.com/board/lists/?id=japanese", "mo": "https://m.dcinside.com/board/japanese"},
    {"name": "ì„ìš©ê³ ì‹œê°¤ëŸ¬ë¦¬", "pc": "https://gall.dcinside.com/board/lists/?id=imyoung", "mo": "https://m.dcinside.com/board/imyoung"},
    {"name": "ìê²©ì¦ê°¤ëŸ¬ë¦¬", "pc": "https://gall.dcinside.com/board/lists/?id=coq", "mo": "https://m.dcinside.com/board/coq"},
    {"name": "ì „ì‚°ì„¸ë¬´íšŒê³„ê°¤ëŸ¬ë¦¬", "pc": "https://gall.dcinside.com/board/lists/?id=accounting", "mo": "https://m.dcinside.com/board/accounting"},
    {"name": "ì •ë³‘ê¶Œê°¤ëŸ¬ë¦¬", "pc": "https://gall.dcinside.com/board/lists/?id=jeongbk", "mo": "https://m.dcinside.com/board/jeongbk"},
    {"name": "ì¤‘êµ­ì–´ê°¤ëŸ¬ë¦¬", "pc": "https://gall.dcinside.com/board/lists/?id=chinese", "mo": "https://m.dcinside.com/board/chinese"},
    {"name": "ì§€í…”í”„ê°¤ëŸ¬ë¦¬", "pc": "https://gall.dcinside.com/board/lists/?id=gtelf", "mo": "https://m.dcinside.com/board/gtelf"},
    {"name": "ì»´í“¨í„°í™œìš©ëŠ¥ë ¥ê°¤ëŸ¬ë¦¬", "pc": "https://gall.dcinside.com/board/lists/?id=itlicense", "mo": "https://m.dcinside.com/board/itlicense"},
    {"name": "í…ìŠ¤ê°¤ëŸ¬ë¦¬", "pc": "https://gall.dcinside.com/board/lists/?id=teps", "mo": "https://m.dcinside.com/board/teps"},
    {"name": "í† ìµê°¤ëŸ¬ë¦¬", "pc": "https://gall.dcinside.com/board/lists/?id=toeic", "mo": "https://m.dcinside.com/board/toeic"},
    {"name": "í† ìµìŠ¤í”¼í‚¹ê°¤ëŸ¬ë¦¬", "pc": "https://gall.dcinside.com/board/lists/?id=toespic", "mo": "https://m.dcinside.com/board/toespic"},
    {"name": "í† í”Œê°¤ëŸ¬ë¦¬", "pc": "https://gall.dcinside.com/board/lists/?id=toefl", "mo": "https://m.dcinside.com/board/toefl"},
    {"name": "í¸ì…ê°¤ëŸ¬ë¦¬", "pc": "https://gall.dcinside.com/board/lists/?id=admission", "mo": "https://m.dcinside.com/board/admission"},
    {"name": "í•™ì ì€í–‰ì œê°¤ëŸ¬ë¦¬", "pc": "https://gall.dcinside.com/board/lists/?id=acbs", "mo": "https://m.dcinside.com/board/acbs"},
    {"name": "í•´ì–‘ê²½ì°°ê°¤ëŸ¬ë¦¬", "pc": "https://gall.dcinside.com/board/lists/?id=kcg", "mo": "https://m.dcinside.com/board/kcg"},
    {"name": "íšŒê³„ì‚¬ê°¤ëŸ¬ë¦¬", "pc": "https://gall.dcinside.com/board/lists/?id=cpa", "mo": "https://m.dcinside.com/board/cpa"}
]

# ğŸš€ 10ëŒ€ ì„œë²„ ì™„ë²½ ë¶„ë°° ê³µì‹
CHUNK_INDEX = int(os.getenv("CHUNK_INDEX", 0))
TOTAL_CHUNKS = int(os.getenv("TOTAL_CHUNKS", 1))

base_size = len(ALL_GALLERIES) // TOTAL_CHUNKS 
remainder = len(ALL_GALLERIES) % TOTAL_CHUNKS   

if CHUNK_INDEX < remainder:
    start_idx = CHUNK_INDEX * (base_size + 1)
    end_idx = start_idx + (base_size + 1)
else:
    start_idx = remainder * (base_size + 1) + (CHUNK_INDEX - remainder) * base_size
    end_idx = start_idx + base_size

TARGET_GALLERIES = ALL_GALLERIES[start_idx:end_idx]

def safe_batch_upload(ws, data_chunk):
    if not data_chunk: return
    rows = [[d['date'], d['gallery'], d['env'], d['pos'], d['url'], d['img'], d['text']] for d in data_chunk]
    for i in range(0, len(rows), 30):
        try:
            ws.append_rows(rows[i:i+30])
            time.sleep(1.5)
        except Exception: time.sleep(5)

async def uploader_worker(queue, ws):
    buffer = []
    while True:
        item = await queue.get()
        if item is None: break
        buffer.append(item)
        if len(buffer) >= 100:
            print(f"ğŸš€ [ì„œë²„ {CHUNK_INDEX+1}] 100ê°œ ë„ë‹¬! ì¤‘ê°„ ì—…ë¡œë“œ ì¤‘...")
            await asyncio.to_thread(safe_batch_upload, ws, buffer)
            buffer.clear()
        queue.task_done()
    if buffer:
        await asyncio.to_thread(safe_batch_upload, ws, buffer)

def get_korean_position(env, page_type, raw_pos, img_src):
    raw = str(raw_pos).lower()
    if not img_src: return "í…ìŠ¤íŠ¸ë°°ë„ˆ"
    if "icon" in raw or "float" in raw or "pop-layer" in raw: return "ì•„ì´ì½˜ë°°ë„ˆ"
    if env == "PC":
        if page_type == "ë³¸ë¬¸": return "í•˜ë‹¨ë°°ë„ˆ" if "bottom" in raw or "btm" in raw else "ê²Œì‹œê¸€ë°°ë„ˆ"
        else:
            if "right" in raw or "wing" in raw: return "ìš°ì¸¡ë°°ë„ˆ"
            if "left" in raw: return "ì¢Œì¸¡ë°°ë„ˆ"
            return "í•˜ë‹¨ë°°ë„ˆ" if "bottom" in raw or "btm" in raw else "ìƒë‹¨ë°°ë„ˆ"
    else: 
        if page_type == "ë³¸ë¬¸": return "í•˜ë‹¨ë°°ë„ˆ" if "bottom" in raw or "btm" in raw else "ê²Œì‹œê¸€ë°°ë„ˆ"
        else: return "í•˜ë‹¨ë°°ë„ˆ" if "bottom" in raw or "btm" in raw else "ìƒë‹¨ë°°ë„ˆ"

async def get_final_landing_url(context, redirect_url):
    if not redirect_url or "addc.dcinside" not in redirect_url: return redirect_url
    try:
        temp = await context.new_page()
        await temp.goto(redirect_url, wait_until="commit", timeout=4000)
        url = temp.url
        await temp.close()
        return url
    except: return redirect_url

async def block_resources(route):
    if route.request.resource_type in ["font", "media"]: await route.abort()
    else: await route.continue_()

async def capture_ads(context, page, env, gallery, page_type):
    collected, seen = [], set()
    today = datetime.now().strftime("%Y-%m-%d")
    
    # â±ï¸ ëŒ€ê¸° ë¬´í•œë£¨í”„ ë°©ì§€ë¥¼ ìœ„í•´ ì‹œë„ íšŸìˆ˜ ì ì ˆíˆ ì œí•œ
    valid_refreshes, attempt = 0, 0
    prefix = f"[ì„œë²„ {CHUNK_INDEX+1}|{env}|{gallery[:4]}|{page_type}]"
    
    while valid_refreshes < 7 and attempt < 15:
        attempt += 1; found_ad_in_this_round = False
        current_round = valid_refreshes + 1
        ad_count_in_round = 0
        try:
            # ğŸ”¥ ì§€ì—° ë¡œë”© ë°©ì–´: í˜ì´ì§€ ì „ì²´ ë¡œë”© ëŒ€ê¸° í›„ ìŠ¤í¬ë¡¤ì„ 3ë‹¨ê³„ë¡œ ë‚´ë¦¼
            await page.reload(wait_until="load", timeout=15000)
            await asyncio.sleep(2.5)
            
            await page.evaluate("window.scrollTo(0, document.body.scrollHeight / 3);")
            await asyncio.sleep(0.5)
            await page.evaluate("window.scrollTo(0, document.body.scrollHeight / 1.5);")
            await asyncio.sleep(0.5)
            await page.evaluate("window.scrollTo(0, document.body.scrollHeight);")
            await asyncio.sleep(1)
        except: pass

        for frame in page.frames:
            try:
                for ad in await frame.locator("a").all():
                    href = await ad.get_attribute("href") or ""
                    clean_href = href.strip().lower()
                    
                    # ğŸš« 1. ì“°ë ˆê¸° ë§í¬ 1ì°¨ ì°¨ë‹¨
                    if not clean_href or clean_href == "#" or "javascript" in clean_href: continue
                    if "__click__" in clean_href or "null" in clean_href: continue
                    
                    # ğŸš« 2. ë””ì‹œ ë‚´ë¶€ êµ¬ì¡° ë§í¬ ì°¨ë‹¨
                    stripped_href = clean_href.rstrip('/')
                    if stripped_href in ["https://www.dcinside.com", "https://gall.dcinside.com", "https://m.dcinside.com", "https://gall.dcinside.com/m"]: continue
                    if any(x in clean_href for x in ["/board/dcbest", "policy", "useinfo", "gall.dcinside.com/mini"]): continue

                    # ğŸ–¼ï¸ ìˆ¨ì€ ì´ë¯¸ì§€ ì¶”ì¶œ ì™„ë²½ ë¶„ì„
                    img_src = await ad.evaluate("""n => {
                        let img = n.querySelector('img');
                        if (img) {
                            if (img.src && !img.src.includes('data:image')) return img.src;
                            if (img.getAttribute('data-src')) return img.getAttribute('data-src');
                        }
                        let bg = window.getComputedStyle(n).backgroundImage;
                        if (bg && bg !== 'none' && bg.includes('url')) {
                            return bg.replace(/^url\\(['"]?/, '').replace(/['"]?\\)$/, '');
                        }
                        let child = n.querySelector('div, span');
                        if (child) {
                            let cbg = window.getComputedStyle(child).backgroundImage;
                            if (cbg && cbg !== 'none' && cbg.includes('url')) {
                                return cbg.replace(/^url\\(['"]?/, '').replace(/['"]?\\)$/, '');
                            }
                        }
                        return '';
                    }""")
                    
                    raw_pos = await ad.evaluate("n => { let p = n.closest('div'); return p ? p.className : ''; }")
                    txt = await ad.inner_text() or ""
                    
                    clean_img = img_src.strip().lower()
                    clean_txt = txt.strip()
                    
                    # ğŸš« 3. ë””ìì¸ UI ìš”ì†Œ ì›ì²œ ì°¨ë‹¨
                    junk_images = ["noimage", "tit_", "sp_", "logo", "g_img", "blank", "/images/"]
                    if any(j in clean_img for j in junk_images) and "/ad/" not in clean_img: continue
                    if "close" in clean_img or "googleactiveview" in str(raw_pos).lower(): continue
                    
                    # ğŸš« 4. í…ìŠ¤íŠ¸ UI ì›ì²œ ì°¨ë‹¨
                    junk_texts = ["ê°¤ëŸ¬ë¦¬", "ë§ˆì´ë„ˆ ê°¤ëŸ¬ë¦¬", "ì‹¤ì‹œê°„ ë² ìŠ¤íŠ¸", "null", "dcinside.com"]
                    if clean_txt in junk_texts: continue
                    if "ì´ìš©ì•ˆë‚´" in clean_txt or "ê°œì¸ì •ë³´" in clean_txt: continue

                    # âœ… 5. ìµœì¢… ê´‘ê³  ì—¬ë¶€ í™•ì¸
                    if any(k in href or k in img_src for k in ["addc.dc", "NetInsight", "nstatic", "toast"]):
                        if not clean_img and not clean_txt: continue
                        
                        found_ad_in_this_round = True
                        key = clean_img or href
                        if key not in seen:
                            seen.add(key)
                            ad_count_in_round += 1
                            final_url = await get_final_landing_url(context, href)
                            
                            # ëœë”© URL ìµœì¢… ê²€ì¦ (ë””ì‹œ ë©”ì¸ìœ¼ë¡œ íŠ•ê¸°ë©´ ë²„ë¦¼)
                            clean_final = final_url.rstrip('/').lower() if final_url else ""
                            if "null" in clean_final or "__click__" in clean_final: continue
                            if clean_final in ["https://www.dcinside.com", "https://gall.dcinside.com", "https://m.dcinside.com", "https://gall.dcinside.com/m"]: continue
                            
                            pos = get_korean_position(env, page_type, raw_pos, clean_img)
                            text_val = clean_txt if clean_txt else "ì´ë¯¸ì§€ ë°°ë„ˆ"
                            
                            print(f"âœ… {prefix} [{current_round}íšŒì°¨ ìƒˆë¡œê³ ì¹¨ - {ad_count_in_round}ë²ˆì§¸ ë°œê²¬] {pos}")
                            collected.append({"date": today, "gallery": gallery, "env": env, "pos": pos, "url": final_url, "img": img_src.strip(), "text": text_val})
            except: continue
        if found_ad_in_this_round: valid_refreshes += 1
    return collected

async def task_runner(sem, ctx, env, tgt, queue):
    async with sem:
        await asyncio.sleep(random.uniform(0, 1.5))
        page = await ctx.new_page()
        await page.route("**/*", block_resources)
        try:
            target_url = tgt['pc'] if env=="PC" else tgt['mo']
            await page.goto(target_url, wait_until="load", timeout=15000)
            await asyncio.sleep(1.5)
            
            # ğŸ”¥ [ì™„ë²½ ìš°íšŒ ì‹œìŠ¤í…œ] íŠ•ê¸°ë©´ ì •ê·œ -> ë§ˆì´ë„ˆ -> ë¯¸ë‹ˆ ìˆœì„œë¡œ ëê¹Œì§€ ì¶”ì !
            current_url = page.url.rstrip('/').lower()
            bounce_urls = ["https://gall.dcinside.com", "http://gall.dcinside.com", "https://www.dcinside.com", "https://m.dcinside.com"]
            
            if env == "PC" and current_url in bounce_urls:
                print(f"âš ï¸ [ì„œë²„ {CHUNK_INDEX+1}|{tgt['name']}] ì •ê·œ ê°¤ëŸ¬ë¦¬ ì•„ë‹˜. ë§ˆì´ë„ˆ ê°¤ëŸ¬ë¦¬ë¡œ 1ì°¨ ìš°íšŒ ì‹œë„...")
                target_url = target_url.replace("/board/lists/?", "/mgallery/board/lists/?")
                await page.goto(target_url, wait_until="load", timeout=15000)
                await asyncio.sleep(1.5)
                
                # ë§ˆì´ë„ˆì—ì„œë„ íŠ•ê¸°ë©´ ë¯¸ë‹ˆ ê°¤ëŸ¬ë¦¬ë¡œ 2ì°¨ ìš°íšŒ
                current_url = page.url.rstrip('/').lower()
                if current_url in bounce_urls:
                    print(f"ğŸš¨ [ì„œë²„ {CHUNK_INDEX+1}|{tgt['name']}] ë§ˆì´ë„ˆ ê°¤ëŸ¬ë¦¬ë„ ì•„ë‹˜. ë¯¸ë‹ˆ ê°¤ëŸ¬ë¦¬ë¡œ ìµœì¢… ìš°íšŒ ì‹œë„...")
                    target_url = target_url.replace("/mgallery/board/lists/?", "/mini/board/lists/?")
                    await page.goto(target_url, wait_until="load", timeout=15000)
                    await asyncio.sleep(1.5)
            
            elif env == "MO" and current_url in bounce_urls:
                # ëª¨ë°”ì¼ í™˜ê²½ì—ì„œ íŠ•ê¸¸ ê²½ìš° ë¯¸ë‹ˆ ê°¤ëŸ¬ë¦¬ êµ¬ì¡°ë¡œ ì¹˜í™˜
                print(f"ğŸš¨ [ì„œë²„ {CHUNK_INDEX+1}|{tgt['name']}] ëª¨ë°”ì¼ ë©”ì¸ íŠ•ê¹€. ë¯¸ë‹ˆ ê°¤ëŸ¬ë¦¬ë¡œ ìš°íšŒ ì‹œë„...")
                target_url = target_url.replace("/board/", "/mini/")
                await page.goto(target_url, wait_until="load", timeout=15000)
                await asyncio.sleep(1.5)

            # ë¦¬ìŠ¤íŠ¸ ê´‘ê³  ìˆ˜ì§‘
            for item in await capture_ads(ctx, page, env, tgt['name'], "ë¦¬ìŠ¤íŠ¸"): await queue.put(item)
            
            # ë³¸ë¬¸ ì§„ì…
            post = page.locator("tr.us-post:not(.notice) td.gall_tit > a:not(.reply_numbox)").first if env=="PC" else page.locator("ul.gall-detail-lst li:not(.notice) .gall-detail-lnktit a").first
            if await post.count() > 0:
                await post.click()
                await asyncio.sleep(2.5)
                for item in await capture_ads(ctx, page, env, tgt['name'], "ë³¸ë¬¸"): await queue.put(item)
        except: pass
        finally: await page.close()

async def main():
    if not TARGET_GALLERIES: return
    
    # ğŸ”¥ í• ë‹¹ëœ ê°¤ëŸ¬ë¦¬ ëª…ë‹¨ ì¶œë ¥ (í„°ë¯¸ë„ì—ì„œ í•œëˆˆì— í™•ì¸ ê°€ëŠ¥)
    gallery_names = [g['name'] for g in TARGET_GALLERIES]
    print(f"ğŸ”¥ [ì„œë²„ {CHUNK_INDEX+1}] ê°€ë™! í• ë‹¹ëœ ê°¤ëŸ¬ë¦¬ {len(TARGET_GALLERIES)}ê°œ: {', '.join(gallery_names)}")
    
    gc = gspread.service_account(filename=SERVICE_ACCOUNT_FILE)
    ws = gc.open_by_url(SHEET_URL).get_worksheet(0)
    
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True, args=["--disable-blink-features=AutomationControlled", "--no-sandbox"])
        pc_ctx, mo_ctx = await browser.new_context(viewport={"width": 1920, "height": 1080}), await browser.new_context(**p.devices['iPhone 13'])
        
        sem, queue = asyncio.Semaphore(5), asyncio.Queue()
        uploader = asyncio.create_task(uploader_worker(queue, ws))

        tasks = [task_runner(sem, pc_ctx, "PC", t, queue) for t in TARGET_GALLERIES] + [task_runner(sem, mo_ctx, "MO", t, queue) for t in TARGET_GALLERIES]
        await asyncio.gather(*tasks)
        await browser.close()
        
        await queue.put(None)
        await uploader
        print(f"ğŸ‰ [ì„œë²„ {CHUNK_INDEX+1}] ë‹´ë‹¹ êµ¬ì—­ ì™„ë²½í•˜ê²Œ ìˆ˜ì§‘ ì¢…ë£Œ!")

if __name__ == "__main__": asyncio.run(main())
